{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RAPPOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the settings for the RAPPOR algorithm itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 128\n",
    "h = 2\n",
    "m = 100\n",
    "f = 0\n",
    "p = 0.65\n",
    "q = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported values can either be hashed using `md5` or `sha256`.\n",
    "In Google's repository, `md5` is used. For generated datasets, the choice shouldn't really matter. For custom datasets, it's important to choose the same hash function that was also used for the data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_function = [\"md5\", \"sha256\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either automatically let this notebook generate data, or load an existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "M = 100\n",
    "distribution = [\"normal\", \"exponential\", \"uniform\", \"zipf1\", \"zipf1.5\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Loading an existing dataset\n",
    "\n",
    "If you already have a dataset that you want to load, change this flag to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clients` should then be a Python list that contains tuples.\n",
    "The first element for each tuple is a numpy array that contains the reported bits. The second element is an integer that describes which cohort the respective user is assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check for specific values, `candidates` should be a list of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset also contains the true counts, `true_counts` can be a list with the true counts for the given candidate strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_counts_available = False\n",
    "true_counts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is automatically generated, `true_counts` is filled with the correct data and `candidates` defaults to all reported values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(\"client/rappor.py\")\n",
    "sc.addPyFile(\"client/hmac_drbg.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rappor import get_bloom_bits as get_bloom_bits_md5\n",
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bloom_bits_sha256(value, cohort, h, k):\n",
    "    bits = []\n",
    "    \n",
    "    for hi in range(h):\n",
    "        seed = str(cohort) + str(hi)\n",
    "        digest = sha256(seed + value).digest()\n",
    "\n",
    "        bit = ord(digest[-1]) % k\n",
    "        bits.append(bit)\n",
    "\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_functions = {\n",
    "    \"sha256\": get_bloom_bits_sha256,\n",
    "    \"md5\": get_bloom_bits_md5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if hash_function in hash_functions:\n",
    "    get_bloom_bits = hash_functions[hash_function]\n",
    "else:\n",
    "    raise NotImplementedError(\"Unimplemented hash function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.stats import rv_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_normal(n, M):\n",
    "    return np.floor(np.random.normal(M / 2, M / 6, size=(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_uniform(n, M):\n",
    "    return np.floor(np.random.uniform(0, M, size=(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_exponential(n, M):\n",
    "    return np.floor(np.random.exponential(scale=M/5, size=(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_custom_zipf(s, n, M):\n",
    "    pdf = 1. / np.array(range(1, M))**float(s)\n",
    "    pdf = pdf / pdf.sum()\n",
    "    distribution = rv_discrete(name='zipf1', values=(range(len(pdf)), pdf))\n",
    "    return distribution.rvs(size=n)\n",
    "\n",
    "def sample_zipf(s):\n",
    "    return partial(sample_custom_zipf, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it doesn't happen often, the distributions above can generate values that are not between $0$ and $M$. In this case, we filter them out and resample new values until we have $n$ valid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_out_of_bounds(seq, lower, upper):\n",
    "    seq = seq[seq >= lower]\n",
    "    seq = seq[seq < upper]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(n, M, distribution=sample_normal):\n",
    "    data = distribution(n, M)\n",
    "    data = filter_out_of_bounds(data, 0, M)\n",
    "    \n",
    "    while len(data) < n:\n",
    "        additional_data = distribution(n - len(data), M)\n",
    "        additional_data = filter_out_of_bounds(additional_data, 0, M)\n",
    "        data = np.append(data, additional_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_candidates(M):\n",
    "    return [\"v%d\" % i for i in range(1, M + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(candidates) == 0:\n",
    "    candidates = generate_candidates(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distribution_map = {\n",
    "    \"normal\": sample_normal,\n",
    "    \"exponential\": sample_exponential,\n",
    "    \"uniform\": sample_uniform,\n",
    "    \"zipf1\": sample_zipf(1),\n",
    "    \"zipf1.5\": sample_zipf(1.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_distribution = distribution_map[distribution]\n",
    "indices = sample(n, M, distribution=used_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reported_values = [candidates[int(i)] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment to cohorts\n",
    "\n",
    "We can reuse the sampling functions we create earlier! Here, all users are assigned to cohorts uniformly randomly. The same logic is used in the shield study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohorts = map(int, sample(n, m, distribution=sample_uniform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating user reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bloom_filter((reported_value, cohort)):\n",
    "    set_bits = get_bloom_bits(reported_value, cohort, h, k)\n",
    "    \n",
    "    bits = np.zeros(k)\n",
    "    bits[set_bits] = 1\n",
    "    \n",
    "    return bits, cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual bits are flipped according to Bernoulli distributions with probabilities $f, p, q$.\n",
    "Because numpy doesn't have helpers for these, we use the equivalent binomial distributions with $n = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bernoulli(p, size):\n",
    "    return np.random.binomial(n=1, p=p, size=(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_prr((bits, cohort)):\n",
    "    randomized_bits = np.where(bernoulli(f, k))[0]\n",
    "    bits[randomized_bits] = bernoulli(0.5, len(randomized_bits))\n",
    "    return bits, cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_irr((bits, cohort)):\n",
    "    result = np.zeros(k)\n",
    "    set_bits = np.where(bits == 1)[0]\n",
    "    unset_bits = np.where(bits == 0)[0]\n",
    "    \n",
    "    result[set_bits] = bernoulli(q, len(set_bits))\n",
    "    result[unset_bits] = bernoulli(p, len(unset_bits))\n",
    "    \n",
    "    return result, cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "    rdd = sc.parallelize(zip(reported_values, cohorts))\n",
    "    rdd = rdd.map(build_bloom_filter).map(build_prr).map(build_irr)\n",
    "    clients = rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "    true_counts = np.zeros(M)\n",
    "    idx, counts = np.unique(indices, return_counts=True)\n",
    "    idx = map(int, idx)\n",
    "    true_counts[idx] = counts\n",
    "    \n",
    "    true_counts_available = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing\n",
    "\n",
    "Individual user reports are not very useful to us, instead we need to sum up how often each bit position was reported.\n",
    "\n",
    "We're using the variable conventions from the paper here. $N$ is a vector containing the number of reports from the individual cohorts. $c$ is a matrix\n",
    "where $c_{ij}$ tells us how often bit $j$ was set in cohort $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = np.zeros((m, k))\n",
    "N = np.zeros(m)\n",
    "\n",
    "for bits, cohort in clients:\n",
    "    c[cohort] += bits\n",
    "    N[cohort] += 1\n",
    "    \n",
    "c = c.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target values `y `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_bloom_count(c, N):\n",
    "    Y = c - ((p + 0.5 * f * q - 0.5 * f * p) * N)\n",
    "    Y /= ((1 - f) * (q - p))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_values(c, N):\n",
    "    Y = estimate_bloom_count(c, N)\n",
    "    return (Y / N).T.reshape(k * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = get_target_values(c, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(candidates):\n",
    "    matrix = []\n",
    "\n",
    "    for cohort in range(m):\n",
    "        rows = []\n",
    "\n",
    "        for candidate in candidates:\n",
    "            bits = np.zeros(k)\n",
    "            bits_set = get_bloom_bits(candidate, cohort, h, k)\n",
    "            bits[bits_set] = 1\n",
    "            rows.append(bits)\n",
    "\n",
    "        for row in np.array(rows).T:\n",
    "            matrix.append(row)\n",
    "\n",
    "    X = np.array(matrix)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = get_features(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import nnls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    x0, _ = nnls(X, y)\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "from numpy.linalg import inv, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "significance_level = 0.05\n",
    "bonferroni_corrected_level = significance_level / M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = X.dot(params)\n",
    "num_datapoints, num_features = X.shape\n",
    "MSE = norm(y - predictions, ord=2)**2 / (num_datapoints - num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = MSE * inv(X.T.dot(X)).diagonal()\n",
    "sd = np.sqrt(var)\n",
    "ts = params / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees_of_freedom = num_datapoints - 1\n",
    "p_values = np.array([2 * (1 - t.cdf(np.abs(i), degrees_of_freedom)) for i in ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "significant_i = np.where(p_values <= bonferroni_corrected_level)[0]\n",
    "significant = params[significant_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzed = np.zeros(M)\n",
    "analyzed[significant_i] = significant\n",
    "estimates = analyzed * N.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_estimate_df(candidates, estimates, original, true_counts_available):\n",
    "    indices = np.argsort(estimates)[::-1]\n",
    "    reported_candidates = [candidates[i] for i in indices]\n",
    "    reported_estimates = np.array(estimates[indices], dtype=np.int32)\n",
    "    \n",
    "    columns = [\"Candidate\", \"Estimated count\"]\n",
    "    \n",
    "    if true_counts_available:\n",
    "        reported_original = np.array(original[indices], dtype=np.int32)\n",
    "        data = np.array(zip(reported_candidates, reported_estimates, reported_original))\n",
    "        columns.append(\"Actual count\")\n",
    "    else:\n",
    "        data = np.array(zip(reported_candidates, reported_estimates))\n",
    "\n",
    "    df = DataFrame(data=data)\n",
    "    df.columns = columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_estimate_df(candidates, estimates, true_counts, true_counts_available).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handles = []\n",
    "labels = []\n",
    "\n",
    "if true_counts_available:\n",
    "    original_bar = plt.bar(range(M), true_counts, width=1., color='orange', edgecolor='darkorange', alpha=0.6)\n",
    "    handles.append(original_bar)\n",
    "    labels.append(\"True\")\n",
    "    \n",
    "reported_bar = plt.bar(range(M), estimates, width=1., color='blue', edgecolor='darkblue', alpha=0.6)\n",
    "handles.append(reported_bar)\n",
    "labels.append(\"Estimated\")\n",
    "\n",
    "plt.title(\"RAPPOR results\")\n",
    "plt.legend(handles, labels, prop={'size': 8})\n",
    "plt.xlabel(\"Index of candidate string\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1249px",
    "left": "0px",
    "right": "2351px",
    "top": "107px",
    "width": "209px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
